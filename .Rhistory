tidy.training <- spam.training %>%
mutate(sms = tolower(str_replace_all(sms, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", '')))
'''
4.Creating the Vocabulary
'''
vocabulary <- c()
messages <- tidy.training$sms
for (m in messages) {
word <- str_split(m, ' ')[[1]]
word <- word[!word %in% '']
vocabulary <- c(vocabulary, word)
}
vocabulary <- unique(vocabulary)
#Cleaned up the vocabulary so it has only unique words.
'''
5. Calculating Constants First
'''
#First thing is to calculate p(Spam) and p(Ham) from the training set.
lbl_percs.tidy.training <- tidy.training %>%
group_by(label) %>%
summarize(Freq = n()) %>%
mutate(Percentage = Freq / nrow(spam) * 100)
total <- as.integer(lbl_percs.tidy.training[1,2] + lbl_percs.tidy.training[2,2])
p_spam <- as.integer(lbl_percs.tidy.training[2,2])/total
p_ham <- as.integer(lbl_percs.tidy.training[1,2])/total
n_of <- function(df, value) {
list <- c()
percs <- df %>%
filter(label == value)
for (p in percs$sms) {#can be changed from sms if you choose to add another variable.
word <- str_split(m, ' ')[[1]]
word <- word[!word %in% '']
list <- c(list, word)
}
return(length(list))
}
n_spam <- n_of(tidy.training, 'spam') #3450
n_ham <- n_of(tidy.training, 'ham') #22020
n_vocabulary <- length(vocabulary) #10573
alpha = 1
'''
6. Calculating Parameters
'''
spam.tidy.training <- tidy.training %>%
filter(label == 'spam')
ham.tidy.training <- tidy.training %>%
filter(label == 'ham')
spam_list <- c()
for (s in spam.tidy.training$sms) {
word <- str_split(s, ' ')[[1]]
word <- word[!word %in% '']
spam_list <- c(spam_list, word)
}
ham_list <- c()
for (h in ham.tidy.training$sms) {
word <- str_split(h, ' ')[[1]]
word <- word[!word %in% '']
ham_list <- c(ham_list, word)
}
word_prob_spam <- data.frame(word = NA,
n_word_given_spam = NA,
p_word_given_spam = NA)
n = 0
for (w in 1:length(vocabulary)) {
for (s in 1:length(spam_list)) {
if (vocabulary[w] == spam_list[s]) {
n = n + 1
} else {
}
}
p_word_given_spam = (n + alpha)/(n_spam + alpha * n_vocabulary)
newdf <- c(vocabulary[w], n, p_word_given_spam)
word_prob_spam <- rbind(word_prob_spam, newdf)
n = 0
}
word_given_spam <- word_given_spam[2:nrow(word_given_spam),]
word_prob_ham <- data.frame(word = NA,
n_word_given_ham = NA,
p_word_given_ham = NA)
n = 0
for (h in 1:length(ham_list)) {
if (vocabulary[w] == ham_list[h]) {
n = n + 1
} else {
}
p_word_given_ham = (n + alpha)/(n_spam + alpha * n_vocabulary)
newdf <- c(vocabulary[w], n, p_word_given_ham)
word_prob_ham <- rbind(word_prob_ham, newdf)
n = 0
}
word_prob_ham <- word_prob_ham[2:nrow(word_prob_ham),]
'''
7. Classifying A New Message
'''
sentence <- sample(spam.training$sms, 1)
p_sentence <- function(sentence) {
sentence <- tolower(str_replace_all(sentence, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
p_spam_given_sentence = 1
p_ham_given_sentence = 1
for (w in 1:length(word)) {
for (p in 1:nrow(word_prob_spam)) {
if (word[w] == word_prob_spam$word[p]) {
p_spam_given_sentence <- p_spam_given_sentence * as.numeric(word_prob$p_word_given_spam[p])
} else {
}
}
for (h in 1:nrow(word_prob_ham)) {
if (word[w] == word_prob_ham$word[p]) {
p_ham_given_sentence <- p_ham_given_sentence * as.numeric(word_prob$p_word_given_ham[h])
} else {
}
}
}
if (p_spam_given_sentence > p_ham_given_sentence) {
return('spam')
} else {
return('ham')
}
}
spam.training <- spam.training %>%
mutate(classifier = map(spam.training$sms, p_sentence))
items <- data.frame(sentence = NA, classifier = NA)
for (i in 680:690) {
item <- c(spam.training$sms[i], map(spam.training$sms[i], p_sentence))
items <- rbind(items, item)
}
map(spam.training$sms[685], p_sentence)
p_sentence(spam.training$sms[685])
sentence <- tolower(str_replace_all(spam.training$sms[685], "([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~])+", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
print(word)
'''
Guided Project: Building a Spam Filter with Naive Bayes
Introduction:
The goal of this project is to create a model program that allows the user to differenciate between spam and non-spam SMS messages given 5572
SMS messages provided.
'''
library(tidyverse)
library(readr)
library(dplyr)
set.seed(1)
spam <- read.csv('~/Google Drive/Work/Data Analyst in R/Guided Projects/Spam Filter/SMSSpamCollection',
sep = '\t',
header = FALSE,
stringsAsFactors = FALSE)
colnames(spam) <- c('label', 'sms')
spam_range <- 1:nrow(spam) #spam has 3184 rows
#spam_cols <- 1:ncol(spam) #spam has 2 columns
#head(spam, 10)
#lbl_percs <- spam %>%
#  group_by(label) %>%
#  summarize(Freq = n()) %>%
#  mutate(Percentage = Freq / nrow(spam) * 100)
#86.2% of the dataframe spam has ham SMS, while 13.8% are spam
'''
2. Training, Cross-validation and Test Sets
'''
dummy_range <- spam_range
non_dupli <- function(sample, list) { #removes numbers from a list of integers to prevent duplication
sample <- sort(sample)
n <- list[-sample]
}
train <- sample(dummy_range, 2547, replace = FALSE)
cross <- sample(dummy_range <- non_dupli(train, dummy_range),
318, replace = FALSE)
test <- sample(dummy_range <- non_dupli(cross, dummy_range),
319, replace = FALSE)
#total <- sort(c(train, cross, test))
#spam_range == total #Both the spam_range and 3 sets match up.
spam.training <- spam[train,]
spam.cross_valid <- spam[cross,]
spam.testing <- spam[test,]
'''
3. Data Cleaning
'''
tidy.training <- spam.training %>%
mutate(sms = tolower(str_replace_all(sms, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", '')))
'''
4.Creating the Vocabulary
'''
vocabulary <- c()
messages <- tidy.training$sms
for (m in messages) {
word <- str_split(m, ' ')[[1]]
word <- word[!word %in% '']
vocabulary <- c(vocabulary, word)
}
vocabulary <- unique(vocabulary)
#Cleaned up the vocabulary so it has only unique words.
'''
5. Calculating Constants First
'''
#First thing is to calculate p(Spam) and p(Ham) from the training set.
lbl_percs.tidy.training <- tidy.training %>%
group_by(label) %>%
summarize(Freq = n()) %>%
mutate(Percentage = Freq / nrow(spam) * 100)
total <- as.integer(lbl_percs.tidy.training[1,2] + lbl_percs.tidy.training[2,2])
p_spam <- as.integer(lbl_percs.tidy.training[2,2])/total
p_ham <- as.integer(lbl_percs.tidy.training[1,2])/total
n_of <- function(df, value) {
list <- c()
percs <- df %>%
filter(label == value)
for (p in percs$sms) {#can be changed from sms if you choose to add another variable.
word <- str_split(m, ' ')[[1]]
word <- word[!word %in% '']
list <- c(list, word)
}
return(length(list))
}
n_spam <- n_of(tidy.training, 'spam') #3450
n_ham <- n_of(tidy.training, 'ham') #22020
n_vocabulary <- length(vocabulary) #10573
alpha = 1
'''
6. Calculating Parameters
'''
spam.tidy.training <- tidy.training %>%
filter(label == 'spam')
ham.tidy.training <- tidy.training %>%
filter(label == 'ham')
spam_list <- c()
for (s in spam.tidy.training$sms) {
word <- str_split(s, ' ')[[1]]
word <- word[!word %in% '']
spam_list <- c(spam_list, word)
}
ham_list <- c()
for (h in ham.tidy.training$sms) {
word <- str_split(h, ' ')[[1]]
word <- word[!word %in% '']
ham_list <- c(ham_list, word)
}
word_prob_spam <- data.frame(word = NA,
n_word_given_spam = NA,
p_word_given_spam = NA)
n = 0
for (w in 1:length(vocabulary)) {
for (s in 1:length(spam_list)) {
if (vocabulary[w] == spam_list[s]) {
n = n + 1
} else {
}
}
p_word_given_spam = (n + alpha)/(n_spam + alpha * n_vocabulary)
newdf <- c(vocabulary[w], n, p_word_given_spam)
word_prob_spam <- rbind(word_prob_spam, newdf)
n = 0
}
word_prob_spam <- word_prob_spam[2:nrow(word_prob_spam),]
word_prob_ham <- data.frame(word = NA,
n_word_given_ham = NA,
p_word_given_ham = NA)
n = 0
for (h in 1:length(ham_list)) {
if (vocabulary[w] == ham_list[h]) {
n = n + 1
} else {
}
p_word_given_ham = (n + alpha)/(n_spam + alpha * n_vocabulary)
newdf <- c(vocabulary[w], n, p_word_given_ham)
word_prob_ham <- rbind(word_prob_ham, newdf)
n = 0
}
word_prob_ham <- word_prob_ham[2:nrow(word_prob_ham),]
'''
7. Classifying A New Message
'''
sentence <- sample(spam.training$sms, 1)
p_sentence <- function(sentence) {
sentence <- tolower(str_replace_all(sentence, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
p_spam_given_sentence = 1
p_ham_given_sentence = 1
for (w in 1:length(word)) {
for (p in 1:nrow(word_prob_spam)) {
if (word[w] == word_prob_spam$word[p]) {
p_spam_given_sentence <- p_spam_given_sentence * as.numeric(word_prob$p_word_given_spam[p])
} else {
}
}
for (h in 1:nrow(word_prob_ham)) {
if (word[w] == word_prob_ham$word[h]) {
p_ham_given_sentence <- p_ham_given_sentence * as.numeric(word_prob$p_word_given_ham[h])
} else {
}
}
}
if (p_spam_given_sentence > p_ham_given_sentence) {
return('spam')
} else {
return('ham')
}
}
spam.training <- spam.training %>%
mutate(classifier = map(spam.training$sms, p_sentence))
items <- data.frame(sentence = NA, classifier = NA)
for (i in 680:690) {
item <- c(spam.training$sms[i], map(spam.training$sms[i], p_sentence))
items <- rbind(items, item)
}
map(spam.training$sms[685], p_sentence)
p_sentence(spam.training$sms[685])
sentence <- tolower(str_replace_all(spam.training$sms[685], "([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~])+", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
print(word)
p_sentence <- function(sentence) {
sentence <- tolower(str_replace_all(sentence, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
p_spam_given_sentence = 1
p_ham_given_sentence = 1
for (w in 1:length(word)) {
for (p in 1:nrow(word_prob_spam)) {
if (word[w] == word_prob_spam$word[p]) {
p_spam_given_sentence <- p_spam_given_sentence * as.numeric(word_prob_spam$p_word_given_spam[p])
} else {
}
}
for (h in 1:nrow(word_prob_ham)) {
if (word[w] == word_prob_ham$word[h]) {
p_ham_given_sentence <- p_ham_given_sentence * as.numeric(word_prob_ham$p_word_given_ham[h])
} else {
}
}
}
if (p_spam_given_sentence > p_ham_given_sentence) {
return('spam')
} else {
return('ham')
}
}
spam.training <- spam.training %>%
mutate(classifier = map(spam.training$sms, p_sentence))
p_sentence(spam.training$sms[685])
spam.training$sms[685]
p_sentence <- function(sentence) {
sentence <- tolower(str_replace_all(sentence, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
print(word)
p_spam_given_sentence = 1
p_ham_given_sentence = 1
for (w in 1:length(word)) {
for (p in 1:nrow(word_prob_spam)) {
if (word[w] == word_prob_spam$word[p]) {
p_spam_given_sentence <- p_spam_given_sentence * as.numeric(word_prob_spam$p_word_given_spam[p])
} else {
}
}
for (h in 1:nrow(word_prob_ham)) {
if (word[w] == word_prob_ham$word[h]) {
p_ham_given_sentence <- p_ham_given_sentence * as.numeric(word_prob_ham$p_word_given_ham[h])
} else {
}
}
}
if (p_spam_given_sentence > p_ham_given_sentence) {
return('spam')
} else {
return('ham')
}
}
p_sentence(spam.training$sms[685])
character(0) == word_prob_spam$word[1]
logical(0)
logical(0) == FALSE
sentence <- sample(spam.training$sms, 1)
FALSE == FALSE
sentence <- tolower(str_replace_all(spam.training$sms[685], "([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~])+", ''))
word <- str_split(sentence, ' ')[[1]]
print(word)
word <- word[!word %in% '']
print(word)
View(word_prob_spam)
character(0) == ''
character(0) == character(0)
character(0) != character(0)
sentence <- tolower(str_replace_all(spam.training$sms[685], "([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~])+", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
print(word)
character(0)
View(spam.training)
View(spam.training)
spam.training$sms[686]
p_sentence <- function(sentence) {
sentence <- tolower(str_replace_all(sentence, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
print(word)
p_spam_given_sentence = 1
p_ham_given_sentence = 1
if (identical(word, character(0))) {
return('ham')
} else {
for (w in 1:length(word)) {
for (p in 1:nrow(word_prob_spam)) {
if (word[w] == word_prob_spam$word[p]) {
p_spam_given_sentence <- p_spam_given_sentence * as.numeric(word_prob_spam$p_word_given_spam[p])
} else {
}
}
for (h in 1:nrow(word_prob_ham)) {
if (word[w] == word_prob_ham$word[h]) {
p_ham_given_sentence <- p_ham_given_sentence * as.numeric(word_prob_ham$p_word_given_ham[h])
} else {
}
}
}
if (p_spam_given_sentence > p_ham_given_sentence) {
return('spam')
} else {
return('ham')
}
}
}
p_sentence(spam.training$sms[685])
for (i in 680:690) {
item <- c(spam.training$sms[i], map(spam.training$sms[i], p_sentence))
items <- rbind(items, item)
}
items <- data.frame(sentence = NA, classifier = NA)
for (i in 680:690) {
item <- c(spam.training$sms[i], map(spam.training$sms[i], p_sentence))
items <- rbind(items, item)
}
p_sentence <- function(sentence) {
sentence <- tolower(str_replace_all(sentence, "(([!\\#$%&'()*+,\\-./:;<=>?@\\[\\]^_‘{|}~£])+|(\u0092s)|)", ''))
word <- str_split(sentence, ' ')[[1]]
word <- word[!word %in% '']
p_spam_given_sentence = 1
p_ham_given_sentence = 1
if (identical(word, character(0))) {
return('ham')
} else {
for (w in 1:length(word)) {
for (p in 1:nrow(word_prob_spam)) {
if (word[w] == word_prob_spam$word[p]) {
p_spam_given_sentence <- p_spam_given_sentence * as.numeric(word_prob_spam$p_word_given_spam[p])
} else {
}
}
for (h in 1:nrow(word_prob_ham)) {
if (word[w] == word_prob_ham$word[h]) {
p_ham_given_sentence <- p_ham_given_sentence * as.numeric(word_prob_ham$p_word_given_ham[h])
} else {
}
}
}
if (p_spam_given_sentence > p_ham_given_sentence) {
return('spam')
} else {
return('ham')
}
}
}
for (i in 680:690) {
item <- c(spam.training$sms[i], map(spam.training$sms[i], p_sentence))
items <- rbind(items, item)
}
items <- data.frame(sentence = NA, classifier = NA)
for (i in 680:690) {
item <- c(spam.training$sms[i], map(spam.training$sms[i], p_sentence))
items <- rbind(items, item)
}
View(items)
spam.training <- spam.training %>%
mutate(classifier = map(spam.training$sms, p_sentence))
training_list <- map(spam.training$sms, p_sentence)
training_list <- map(spam.training$sms[1:1000], p_sentence)
map(spam.training$sms[685], p_sentence)
p_sentence(spam.training$sms[685])
map(spam.training$sms[685], p_sentence)
p_sentence(spam.training$sms[685])
map(spam.training$sms[685], p_sentence)
p_sentence(spam.training$sms[685])
training_list <- map(spam.training$sms[1:500], p_sentence)
training_list <- map(spam.training$sms[1:10], p_sentence)
spam.training <- spam.training %>%
mutate(classifier = map(spam.training$sms, p_sentence))
memory.limit()
mem.limits()
gc()
spam.training <- spam.training %>%
mutate(classifier = map(spam.training$sms, p_sentence))
start_time <- Sys.time()
spam.training <- spam.training %>%
mutate(classifier = map(spam.training$sms, p_sentence))
end_time <- Sys.time()
time_diff <- start_time - end_time
start_time <- Sys.time()
list <- c()
for (i in 1:nrow(spam.training)) {
list <- c(list, map(spam.training$sms[i], p_sentence))
}
end_time <- Sys.time()
View(spam.training)
View(lbl_percs.tidy.training)
list <- c()
start_time <- Sys.time()
list <- c()
for (i in 1:nrow(spam.training)) {
list <- c(list, map(spam.training$sms[i], p_sentence))
}
end_time <- Sys.time()
